{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import folium\n",
    "import gmaps\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "# Import API key\n",
    "from config import gkey\n",
    "from countryinfo import CountryInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy's code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naturalization - overall data table cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load naturalization table\n",
    "nat_file = 'naturalization_totals_1907-2018_yb2018.xlsx'\n",
    "filepath = os.path.join('.', 'Resources', nat_file)\n",
    "\n",
    "naturalization = pd.read_excel(filepath, header=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop notes data at end of document\n",
    "naturalization.drop(labels=range(112,118), inplace=True)\n",
    "naturalization.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "naturalization.rename(columns={\n",
    "    'filed': 'Petitions filed',\n",
    "    'Total': 'Naturalized, total',\n",
    "    'denied': 'Petitions denied'\n",
    "}, inplace=True)\n",
    "\n",
    "# Drop unneeded columns\n",
    "naturalization = naturalization.drop(labels=['Civilian', 'Military 2', 'Not reported'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find funny/footnoted years and fix them\n",
    "for index, row in naturalization.iterrows():\n",
    "    \n",
    "    year = naturalization.loc[index, 'Year']\n",
    "    \n",
    "    if len(str(year)) > 4:\n",
    "        year = int(year[0:5])\n",
    "        naturalization.loc[index, 'Year'] = year\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "# Set year as index\n",
    "naturalization.set_index(keys=['Year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change datatype to int for all columns\n",
    "for c in naturalization.columns:\n",
    "    naturalization[c] = naturalization[c].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned naturalization data to df\n",
    "\n",
    "filename = 'naturalization_filed_denied.csv'\n",
    "path = os.path.join('.', 'Output_files', filename)\n",
    "naturalization.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naturalization - by country data cleaning & merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in files\n",
    "\n",
    "filename = 'naturalization_bycountry_2009-2018_table21d_yb2018.xlsx'\n",
    "filepath = os.path.join('.', 'Resources', filename)\n",
    "nat_country_20092018 = pd.read_excel(filepath, header=3)\n",
    "\n",
    "filename = 'naturalization_bycountry_2000-2009_table21d_yb2009.xls'\n",
    "filepath = os.path.join('.', 'Resources', filename)\n",
    "nat_country_20002009 = pd.read_excel(filepath, header=3)\n",
    "\n",
    "filename = 'naturalization_bycountry_1990-1999_table46_yb1999.xlsx'\n",
    "filepath = os.path.join('.', 'Resources', filename)\n",
    "nat_country_19901999 = pd.read_excel(filepath, header=4)\n",
    "\n",
    "nat_country_dfs = [nat_country_20092018, nat_country_20002009, nat_country_19901999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop buffer row at start\n",
    "for df in nat_country_dfs:\n",
    "    df.drop([0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop trailing rows w/ descriptive info\n",
    "nat_country_19901999.drop(labels=range(204,211), inplace=True)\n",
    "nat_country_20002009.drop(labels=range(212,220), inplace=True)\n",
    "nat_country_20092018.drop(labels=range(212,219), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop region information\n",
    "nat_country_20002009.drop(index=range(1,10), inplace=True)\n",
    "nat_country_20092018.drop(index=range(1,10), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize column naming\n",
    "nat_country_19901999.rename(columns={\n",
    "    'former allegiance': 'Country'\n",
    "}, inplace=True)\n",
    "nat_country_20002009.rename(columns={\n",
    "    'Region and country of birth': 'Country'\n",
    "}, inplace=True)\n",
    "nat_country_20092018.rename(columns={\n",
    "    'Region and country of birth': 'Country'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge data\n",
    "nat_country = nat_country_19901999.merge(nat_country_20002009, how='outer', on='Country')\n",
    "nat_country = nat_country.merge(nat_country_20092018, how='outer', on='Country')\n",
    "nat_country.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaNs\n",
    "nat_country.fillna(0, inplace=True)\n",
    "nat_country.replace({'X': 0, '-': 0, 'D': 0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop region names from df\n",
    "nat_country.drop(index=[1, 54, 94, 148, 163, 180, 188], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index as country names\n",
    "nat_country.set_index(keys='Country', inplace=True)\n",
    "\n",
    "# Convert datatype to integer\n",
    "nat_country.astype('int64').dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Reset max col and row view, to find and fix errant chars\n",
    "# pd.set_option('display.max_rows', None)\n",
    "# pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant 2009 columns\n",
    "# Note that  this is a quick-and-dirty drop - simply dropping the 'y' col because it has slightly fewer datapoints\n",
    "# If you compare differences between 2009_x and y, each column reports fewer numbers for around 15 countries\n",
    "# None of these countries are in our samples, so we're not worrying about them right now\n",
    "nat_country.drop(columns=['2009_y'], inplace=True)\n",
    "nat_country.rename(columns={\n",
    "    '2009_x': '2009'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine \"total data\" into \"Grand total\" row and drop partial rows\n",
    "all_countries = nat_country.loc['All countries',:]\n",
    "total_countries = nat_country.loc['Total', :]\n",
    "total_countries_final = all_countries + total_countries\n",
    "\n",
    "total_countries_final_df = total_countries_final.to_frame(name='Grand Total')\n",
    "total_countries_final_df = total_countries_final_df.T\n",
    "\n",
    "nat_country.drop(index=['All countries'], inplace=True)\n",
    "nat_country.drop(index=['Total'], inplace=True)\n",
    "\n",
    "nat_country_df = pd.concat([nat_country, total_countries_final_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the index so easier to read\n",
    "nat_country_df.sort_index(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned and merged by-country naturalization data to df\n",
    "\n",
    "filename = 'naturalization_by_country_merged_1990-2018.csv'\n",
    "path = os.path.join('.', 'Output_files', filename)\n",
    "nat_country_df.to_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asylum seeker demographic data 2018 cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load asylum seeker age/gender/etc table (2018)\n",
    "asy_2018_file = 'fy2018_table18d_asylum_age_etc.xlsx'\n",
    "filepath = os.path.join('.', 'Resources', asy_2018_file)\n",
    "\n",
    "asylum_2018 = pd.read_excel(filepath, header=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum_2018.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop notes data at end of document\n",
    "asylum_2018.drop(labels=range(34,38), inplace=True)\n",
    "asylum_2018.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sex [5:8], rename column\n",
    "asylum_2018_sex = asylum_2018.iloc[1:4,0:2]\n",
    "asylum_2018_sex.rename(columns={\n",
    "    \"Characteristic\": \"Sex\"\n",
    "}, inplace=True)\n",
    "\n",
    "# reset index\n",
    "asylum_2018_sex.set_index(keys='Sex', inplace=True)\n",
    "asylum_2018_sex\n",
    "\n",
    "# Rename \"total\" to reflect dataset scope\n",
    "asylum_2018_sex.rename(columns={\n",
    "    \"Total\": \"Asylum 2018\"\n",
    "}, inplace=True)\n",
    "asylum_2018_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out broad age group [27:31]\n",
    "asylum_2018_broad_age = asylum_2018.iloc[22:27,0:2]\n",
    "asylum_2018_broad_age_total = asylum_2018_broad_age.drop([22])\n",
    "asylum_2018_broad_age_total.rename(columns={\n",
    "    \"Characteristic\": \"Age\"\n",
    "}, inplace=True)\n",
    "asylum_2018_broad_age_total.set_index(keys='Age', inplace=True)\n",
    "asylum_2018_broad_age_total\n",
    "\n",
    "# Rename \"total\" to reflect dataset scope\n",
    "asylum_2018_broad_age_total.rename(columns={\n",
    "    \"Total\": \"Asylum 2018\"\n",
    "}, inplace=True)\n",
    "asylum_2018_broad_age_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out marital status [32:38]\n",
    "asylum_2018_marital = asylum_2018.iloc[28:34,0:2]\n",
    "asylum_2018_marital.rename(columns={\n",
    "    \"Characteristic\": \"Marital Status\"\n",
    "}, inplace=True)\n",
    "asylum_2018_marital.set_index(keys='Marital Status', inplace=True)\n",
    "asylum_2018_marital\n",
    "\n",
    "# Rename \"total\" to reflect dataset scope\n",
    "asylum_2018_marital.rename(columns={\n",
    "    \"Total\": \"Asylum 2018\"\n",
    "}, inplace=True)\n",
    "asylum_2018_marital"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asylum seeker demographic data 2009 cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning asylum demographic data from 2009\n",
    "asy_2009_file = 'fy_2009_table15d_asylum_age_etc.xls'\n",
    "filepath = os.path.join('.', 'Resources', asy_2009_file)\n",
    "\n",
    "asylum_2009 = pd.read_excel(filepath, header=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asylum_2009.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop notes data at end of document\n",
    "asylum_2009.drop(labels=range(37,41), inplace=True)\n",
    "asylum_2009.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into sex [5:8], rename column\n",
    "asylum_2009_sex = asylum_2009.iloc[1:4,0:2]\n",
    "asylum_2009_sex.rename(columns={\n",
    "    \"Characteristic\": \"Sex\"\n",
    "}, inplace=True)\n",
    "asylum_2009_sex\n",
    "\n",
    "# Rename \"total\" to reflect dataset scope\n",
    "asylum_2009_sex.rename(columns={\n",
    "    \"Total\": \"Asylum 2009\"\n",
    "}, inplace=True)\n",
    "\n",
    "# reset index\n",
    "asylum_2009_sex.set_index(keys='Sex', inplace=True)\n",
    "asylum_2009_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out broad age group [32:35]\n",
    "asylum_2009_broad_age = asylum_2009.iloc[25:29,0:2]\n",
    "asylum_2009_broad_age.rename(columns={\n",
    "    \"Characteristic\": \"Age\"\n",
    "}, inplace=True)\n",
    "\n",
    "asylum_2009_broad_age['Age'] = asylum_2009_broad_age['Age'].str.strip()\n",
    "asylum_2009_broad_age['Age']\n",
    "\n",
    "asylum_2009_broad_age.set_index(keys='Age', inplace=True)\n",
    "\n",
    "asylum_2009_broad_age.index\n",
    "\n",
    "# Rename \"total\" to reflect dataset scope\n",
    "asylum_2009_broad_age.rename(columns={\n",
    "    \"Total\": \"Asylum 2009\"\n",
    "}, inplace=True)\n",
    "\n",
    "asylum_2009_broad_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split out 2009 marital status\n",
    "asylum_2009_marital = asylum_2009.iloc[31:37,0:2]\n",
    "asylum_2009_marital.rename(columns={\n",
    "    \"Characteristic\": \"Marital Status\"\n",
    "}, inplace=True)\n",
    "asylum_2009_marital.set_index(keys='Marital Status', inplace=True)\n",
    "\n",
    "# Rename \"total\" to reflect dataset scope\n",
    "asylum_2009_marital.rename(columns={\n",
    "    \"Total\": \"Asylum 2009\"\n",
    "}, inplace=True)\n",
    "\n",
    "asylum_2009_marital"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Clean up inconsistencies between df indices\n",
    "# asylum_2009_broad_age.rename({'Under 16': '< 16', \n",
    "#                                           'Age 16 to 20': '16 - 20', \n",
    "#                                           'Age 21 and over': '21+'}, axis='index', inplace=True)\n",
    "\n",
    "# asylum_2018_broad_age_total.rename({'Under 16 years': '< 16', \n",
    "#                                           '16 to 20 years': '16 - 20', \n",
    "#                                           '21 years and over': '21+'}, axis='index', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge LPR and Asyulym seeker datasets\n",
    "\n",
    "# # Join asylum datasets together\n",
    "# lpr_asylum_sex = asylum_2009_sex.merge(asylum_2018_sex, how=\"inner\", left_index=True, right_index=True)\n",
    "# lpr_asylum_age = asylum_2009_broad_age.merge(asylum_2018_broad_age_total, how=\"inner\", left_index=True, right_index=True)\n",
    "# lpr_asylum_marital = asylum_2009_marital.merge(asylum_2018_marital, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpr_asylum_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kana's code starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Immigrants by State - overall data table cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read bystate csv data\n",
    "bystate = pd.read_csv(\"Resources/By state data.csv\")\n",
    "\n",
    "# Dropna\n",
    "bystate = bystate.dropna()\n",
    "\n",
    "# Drop others\n",
    "bystate.drop(bystate.tail(1).index,inplace=True)\n",
    "\n",
    "# Change data to integer\n",
    "bystate.iloc[:,1:20].astype(int)\n",
    "\n",
    "# Show the dataframe\n",
    "bystate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of US state abbreviation\n",
    "us_state_abbrev = {\n",
    "    'Alabama': 'AL',\n",
    "    'Alaska': 'AK',\n",
    "    'Arizona': 'AZ',\n",
    "    'Arkansas': 'AR',\n",
    "    'California': 'CA',\n",
    "    'Colorado': 'CO',\n",
    "    'Connecticut': 'CT',\n",
    "    'Delaware': 'DE',\n",
    "    'District of Columbia': 'DC',\n",
    "    'Florida': 'FL',\n",
    "    'Georgia': 'GA',\n",
    "    'Hawaii': 'HI',\n",
    "    'Idaho': 'ID',\n",
    "    'Illinois': 'IL',\n",
    "    'Indiana': 'IN',\n",
    "    'Iowa': 'IA',\n",
    "    'Kansas': 'KS',\n",
    "    'Kentucky': 'KY',\n",
    "    'Louisiana': 'LA',\n",
    "    'Maine': 'ME',\n",
    "    'Maryland': 'MD',\n",
    "    'Massachusetts': 'MA',\n",
    "    'Michigan': 'MI',\n",
    "    'Minnesota': 'MN',\n",
    "    'Mississippi': 'MS',\n",
    "    'Missouri': 'MO',\n",
    "    'Montana': 'MT',\n",
    "    'Nebraska': 'NE',\n",
    "    'Nevada': 'NV',\n",
    "    'New Hampshire': 'NH',\n",
    "    'New Jersey': 'NJ',\n",
    "    'New Mexico': 'NM',\n",
    "    'New York': 'NY',\n",
    "    'North Carolina': 'NC',\n",
    "    'North Dakota': 'ND',\n",
    "    'Northern Mariana Islands':'MP',\n",
    "    'Ohio': 'OH',\n",
    "    'Oklahoma': 'OK',\n",
    "    'Oregon': 'OR',\n",
    "    'Palau': 'PW',\n",
    "    'Pennsylvania': 'PA',\n",
    "    'Puerto Rico': 'PR',\n",
    "    'Rhode Island': 'RI',\n",
    "    'South Carolina': 'SC',\n",
    "    'South Dakota': 'SD',\n",
    "    'Tennessee': 'TN',\n",
    "    'Texas': 'TX',\n",
    "    'Utah': 'UT',\n",
    "    'Vermont': 'VT',\n",
    "    'Virgin Islands': 'VI',\n",
    "    'Virginia': 'VA',\n",
    "    'Washington': 'WA',\n",
    "    'West Virginia': 'WV',\n",
    "    'Wisconsin': 'WI',\n",
    "    'Wyoming': 'WY',\n",
    "}\n",
    "\n",
    "# Reverse key and value\n",
    "abbrev_us_state = dict(map(reversed, us_state_abbrev.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary list\n",
    "dict_list=[]\n",
    "\n",
    "# For each key and value in dictionary, combine them and add them to a list\n",
    "for key,value in abbrev_us_state.items():\n",
    "    dict_list.append((key,value))\n",
    "    \n",
    "# Print the list\n",
    "print (dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe using dictionary list\n",
    "state_abbrev = pd.DataFrame(dict_list)\n",
    "state_abbrev.columns = [\"Abbrev\",\"State\"]\n",
    "\n",
    "# Show the dataframe\n",
    "state_abbrev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge bystate data and state abbreveation dataframe\n",
    "complete_state_df = pd.merge(bystate, state_abbrev, on = \"State\")\n",
    "\n",
    "# Rename columns\n",
    "complete_state_df = complete_state_df.rename(columns = {\"State\" : \"State Name\",\n",
    "                                                        \"Abbrev\" : \"State\"})\n",
    "\n",
    "# Show the dataframe\n",
    "complete_state_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe \n",
    "output_state = complete_state_df[[\"State\",\"2000\",\"2018\"]]\n",
    "\n",
    "# Change data type\n",
    "convert_dict = {'State': str, \n",
    "                '2000': int,\n",
    "                '2018': int} \n",
    "\n",
    "output_state_df = output_state.astype(convert_dict) \n",
    "\n",
    "# Display dataframe\n",
    "output_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm if data type has been changed \n",
    "output_state_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output cleaned data as csv\n",
    "output_state.to_csv(\"Output_files/Immigrants By State.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kana's code ends here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satish Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import gmaps\n",
    "import os\n",
    "# Import API key\n",
    "from config import gkey\n",
    "from countryinfo import CountryInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_df=pd.read_csv(\"Resources/Permanent_Resident_Years.csv\")\n",
    "immigration_df['Number'] = [x.replace(',', '') for x in immigration_df['Number']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_df.Year=pd.to_numeric(immigration_df.Year)\n",
    "immigration_df.Number=pd.to_numeric(immigration_df.Number)\n",
    "immigration_plt=immigration_df.plot(kind=\"line\", x=\"Year\", y=\"Number\", grid=True, figsize=(15,10),legend=False,title=\"Number of Lawful Permanent Resident Status Vs. Years\")\n",
    "max_arrow_y=immigration_df['Number'].max()\n",
    "max_arrow_x=immigration_df.loc[immigration_df['Number']==max_arrow_y,\"Year\"].reset_index(drop=True)\n",
    "plt.annotate(\n",
    "    f\"maximum {max_arrow_x[0],max_arrow_y}\", \n",
    "    xy=(max_arrow_x[0], max_arrow_y))\n",
    "\n",
    "min_arrow_y=immigration_df['Number'].min()\n",
    "min_arrow_x=immigration_df.loc[immigration_df['Number']==min_arrow_y,\"Year\"].reset_index(drop=True)\n",
    "plt.annotate(\n",
    "    f\"Minimum {min_arrow_x[0],min_arrow_y}\", \n",
    "    xy=(min_arrow_x[0], min_arrow_y))\n",
    "\n",
    "plt.ylabel(\"Number of Lawful Permanent Resident Status\")\n",
    "plt.xlabel(\"Timepoint in Years\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading CSV\n",
    "Country_Data_2018=pd.read_csv(\"Resources/Country_Data_2018.csv\")\n",
    "Country_Data_1999=pd.read_csv(\"Resources/Country_Data_1999.csv\")\n",
    "Country_Data_2009=pd.read_csv(\"Resources/Country_Data_2009.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data cleaning,Removing extra column\n",
    "Country_Data_1999=Country_Data_1999.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing Data which has No value\n",
    "Country_Data_2018_df=Country_Data_2018.dropna()\n",
    "Country_Data_1999_df=Country_Data_1999.dropna()\n",
    "Country_Data_2009_df=Country_Data_2009.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract First Column so that it can be used for Name as Header\n",
    "new_header_2018 = Country_Data_2018_df.iloc[0]\n",
    "new_header_1999 = Country_Data_1999_df.iloc[0]\n",
    "new_header_2009 = Country_Data_2009_df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renaming the Header removing first row\n",
    "Country_Data_2018_df.columns=new_header_2018\n",
    "Country_Data_2018_df=Country_Data_2018_df[10:]\n",
    "Country_Data_2018_df.to_csv('Output_files/Country_Data_2018_df.csv')\n",
    "\n",
    "Country_Data_1999_df.columns=new_header_1999\n",
    "Country_Data_1999_df=Country_Data_1999_df[1:]\n",
    "Country_Data_1999_df.to_csv('Output_files/Country_Data_1999_df.csv')\n",
    "\n",
    "Country_Data_2009_df.columns=new_header_2009\n",
    "Country_Data_2009_df=Country_Data_2009_df[10:]\n",
    "Country_Data_2009_df.to_csv('Output_files/Country_Data_2009_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Countries in central America\n",
    "Central_America_Data=['Mexico', 'Guatemala', 'Honduras', 'Nicaragua', 'El Salvador', 'Costa Rica', 'Panama', 'Belize']\n",
    "#Getting only records of Central America from main Data Set\n",
    "Latin_Data_df=Country_Data_2018_df[Country_Data_2018_df['Region and country of birth'].isin(Central_America_Data)]\n",
    "#Data Cleaning\n",
    "Latin_Data_df=Latin_Data_df.apply(lambda x: x.str.replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new DataFrame for required Data\n",
    "Latin_Data_summ=[['2014',pd.to_numeric(Latin_Data_df['2014']).sum()],['2015',pd.to_numeric(Latin_Data_df['2015']).sum()],['2017',pd.to_numeric(Latin_Data_df['2017']).sum()],['2018',pd.to_numeric(Latin_Data_df['2018']).sum()]]\n",
    "Latin_Data_summ_df=pd.DataFrame(Latin_Data_summ, columns = ['Year', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar Graph showing the Central America and Years\n",
    "Latin_Data_summ_df.plot.bar(x='Year', y='Count', rot=0,legend=False)\n",
    "plt.axis('tight')\n",
    "plt.title(\"Number of Immigrants Vs Year\")\n",
    "plt.ylabel(\"Total Number of Immigrants from Central America\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of Islamic Countries \n",
    "Islam_Country_Data=['Afghanistan','Iran','Yemen','Jordan','Saudi Arabia','Sudan','Pakistan','Syria','Oman']\n",
    "#Data Set till 1999 \n",
    "Islam_Data_1999_df=Country_Data_1999_df[Country_Data_1999_df['Region and country of birth'].isin(Islam_Country_Data)]\n",
    "#Data Cleaning\n",
    "Islam_Data_1999_df=Islam_Data_1999_df.apply(lambda x: x.str.replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Set form 2000 to 2009 \n",
    "Islam_Data_2009_df=Country_Data_2009_df[Country_Data_2009_df['Region and country of birth'].isin(Islam_Country_Data)]\n",
    "#Data Cleaning\n",
    "Islam_Data_2009_df=Islam_Data_2009_df.apply(lambda x: x.str.replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the DataFrame\n",
    "Merge_Islam_Country=pd.merge(Islam_Data_1999_df,Islam_Data_2009_df,how='outer')\n",
    "#New DataFrame with reuqired Dataset\n",
    "Islam_Country_summ=[['1999',pd.to_numeric(Merge_Islam_Country['1999']).sum()],['2000',pd.to_numeric(Merge_Islam_Country['2000']).sum()],['2005',pd.to_numeric(Merge_Islam_Country['2005']).sum()],['20006',pd.to_numeric(Merge_Islam_Country['2006']).sum()]]\n",
    "Islam_Country_summ=pd.DataFrame(Islam_Country_summ, columns = ['Year', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merging the DataFrame\n",
    "Merge_Islam_Country=pd.merge(Islam_Data_1999_df,Islam_Data_2009_df,how='outer')\n",
    "#New DataFrame with reuqired Dataset\n",
    "Islam_Country_summ=[['1999',pd.to_numeric(Merge_Islam_Country['1999']).sum()],['2000',pd.to_numeric(Merge_Islam_Country['2000']).sum()],['2005',pd.to_numeric(Merge_Islam_Country['2005']).sum()],['20006',pd.to_numeric(Merge_Islam_Country['2006']).sum()]]\n",
    "Islam_Country_summ=pd.DataFrame(Islam_Country_summ, columns = ['Year', 'Count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ployyinh the Graph\n",
    "Islam_Country_summ.plot.bar(x='Year', y='Count', rot=0,legend=False)\n",
    "plt.axis('tight')\n",
    "plt.title(\"Number of Immigrants Vs Year\")\n",
    "plt.ylabel(\"Total Number of Immigrants from Arab Countries\")\n",
    "plt.xlabel(\"Year\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country_Data_1999_2009=pd.merge(Country_Data_1999_df,Country_Data_2009_df,how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country_Data_Merged=pd.merge(Country_Data_1999_2009,Country_Data_2018_df,how='outer')\n",
    "Country_Data_Merged=Country_Data_Merged.apply(lambda x: x.str.replace(',',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country_Data_Merged=Country_Data_Merged.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country_Data_Merged.to_csv(\"Output_files/final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country_Data_Merged=Country_Data_Merged.rename(columns = {'1998 1':'1998'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country_Data_Merged_clean=Country_Data_Merged.iloc[:,1:(len(Country_Data_Merged.columns)+1)]\n",
    "header_col=Country_Data_Merged.loc[:,Country_Data_Merged.columns!='Region and country of birth'].columns.tolist()\n",
    "for col_name in header_col:\n",
    "    Country_Data_Merged[col_name]=pd.to_numeric(Country_Data_Merged[col_name],errors='coerce').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Country_Data_Merged.groupby(['Region and country of birth']).sum()\n",
    "Country_Data_Merged['Total']=Country_Data_Merged.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Country_Data_Merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location=[]\n",
    "#For loop to get the latitude and Longitude\n",
    "for x in Country_Data_Merged['Region and country of birth']:\n",
    "    #Get the Lat and Lng from countryinfo package\n",
    "    try:\n",
    "        country = CountryInfo(x).info()['latlng']\n",
    "        location.append(country)\n",
    "   #If Data is not present in the CountryInfo package then check with Geocode API\n",
    "    except KeyError:\n",
    "        base_url=\"https://maps.googleapis.com/maps/api/geocode/json?address=\"\n",
    "        gkey=gkey\n",
    "        final_url=f\"{base_url}{x}&key={gkey}\"\n",
    "        response = requests.get(final_url).json()\n",
    "        #Getting location and saving results\n",
    "        result=response['results'][0]['geometry']['location']\n",
    "        lat=result['lat']\n",
    "        lng=result['lng']\n",
    "        latlng=[lat,lng]\n",
    "        location.append(latlng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new DataFrame for location\n",
    "location_df=pd.DataFrame(location,columns = ['Lat', 'Lng'])\n",
    "Country_Data_Merged['Lat']=location_df['Lat'].astype(float)\n",
    "Country_Data_Merged['Lng']=location_df['Lng'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuring gmpas\n",
    "gmaps.configure(api_key=gkey)\n",
    "\n",
    "fig = gmaps.figure()\n",
    "\n",
    "#Creating Heat Map\n",
    "heat_layer = gmaps.heatmap_layer(location_df, weights=Country_Data_Merged['Total'], \n",
    "                                 dissipating=False, max_intensity=90000,\n",
    "                                 point_radius = 1)\n",
    "#Adding heat maps\n",
    "fig.add_layer(heat_layer)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving final merged copy\n",
    "output_file='Output_files/Country_Data_Merged.csv'\n",
    "Country_Data_Merged.to_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satish end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umar's code starts here\n",
    "#Read in the Excel file and view the headers\n",
    "Lawful_df = pd.read_excel(\"./Resources/fy2018_Lawful.xlsx\", header=4)\n",
    "Lawful_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the iloc function to locate the point of interest in a data set\n",
    "Broad_age = Lawful_df.iloc[19:23,:]\n",
    "Broad_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the characteristic and Total columns \n",
    "Broad_age_df = pd.DataFrame(Broad_age)\n",
    "Sex = Broad_age_df.iloc[:, 0:2]\n",
    "Sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename your columns \n",
    "Cleaned = Sex.rename(columns={\"Characteristic\": \"Age\", \"Total\": \"Lawful 2018\"})\n",
    "Index_age = Cleaned.set_index(\"Age\")\n",
    "Index_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View a single row \n",
    "Sex = Lawful_df.iloc[19,1:]\n",
    "Sex.to_frame(name=\"LPR 2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the iloc function to locate the point of interest in a data set\n",
    "Marital_status = Lawful_df.iloc[24:30,:]\n",
    "Marital_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the characteristic and Total columns \n",
    "New_marital_df = pd.DataFrame(Marital_status)\n",
    "Specific = New_marital_df.iloc[:, 0:2]\n",
    "Specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename your columns \n",
    "Renamed = Specific.rename(columns={\"Characteristic\": \"Marital Status\", \"Total\": \"Lawful Permanent Resident 2018\"})\n",
    "Renamed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View a single column \n",
    "Status = Lawful_df.iloc[24:30,0:2]\n",
    "Name18 = Status.rename(columns={\"Characteristic\": \"Marital Status\", \"Total\": \"Lawful 2018\"})\n",
    "#Set marital status as index for clarity\n",
    "Name18.set_index(\"Marital Status\", inplace=True)\n",
    "Name18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in the Excel file and \n",
    "Lawful09_df = pd.read_excel(\"./Resources/fy2009_Lawful.xls\", header=4)\n",
    "Lawful09_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the iloc function to locate the point of interest in a data set\n",
    "Broad09_age = Lawful09_df.iloc[20:24,:]\n",
    "Broad09_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the characteristic and Total columns \n",
    "Broad09_age_df = pd.DataFrame(Broad09_age)\n",
    "Sex09 = Broad09_age_df.iloc[:, 0:2]\n",
    "Sex09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename your columns \n",
    "Age09 = Sex09.rename(columns={\"Characteristic\": \"Age\", \"Total\": \"Lawful Permanent Resident 2009\"})\n",
    "New_index09 = Age09.set_index(\"Age\")\n",
    "New_index09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the iloc function to locate the point of interest in a data set\n",
    "Broad09_age = Lawful09_df.iloc[20:24,:]\n",
    "Broad09_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the characteristic and Total columns \n",
    "Broad09_age_df = pd.DataFrame(Broad09_age)\n",
    "Sex09 = Broad09_age_df.iloc[:, 0:2]\n",
    "Sex09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename your columns \n",
    "Age09 = Sex09.rename(columns={\"Characteristic\": \"Age\", \"Total\": \"Lawful Permanent Resident 2009\"})\n",
    "New_index09 = Age09.set_index(\"Age\")\n",
    "New_index09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View a single row \n",
    "Sex09 = Lawful09_df.iloc[20,1:]\n",
    "Sex09 = Sex09.to_frame(name=\"LPR 2009\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sex09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use the iloc function to locate the point of interest in a data set\n",
    "Marital09_status = Lawful09_df.iloc[26:32,:]\n",
    "Marital09_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the characteristic and Total columns \n",
    "New09_marital_df = pd.DataFrame(Marital09_status)\n",
    "Specific09 = New09_marital_df.iloc[:, 0:2]\n",
    "Specific09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename your columns \n",
    "Renamed09 = Specific09.rename(columns={\"Characteristic\": \"Marital Status\", \"Total\": \"Lawful Permanent Resident 2009\"})\n",
    "Renamed09.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#View a single column\n",
    "Status09 = Lawful09_df.iloc[26:32,0:2]\n",
    "Name09 = Status09.rename(columns={\"Characteristic\": \"Marital Status\", \"Total\": \"Lawful 2009\"})\n",
    "#Set marital status as index for clarity\n",
    "Name09.set_index(\"Marital Status\", inplace=True)\n",
    "Name09\n",
    "\n",
    "#Umar Code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge LPR and asylum seeker datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy code for merging datasets starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up inconsistencies between df indices and types\n",
    "asylum_2009_broad_age.rename({'Under 16': '< 16', \n",
    "                                          'Age 16 to 20': '16 - 20', \n",
    "                                          'Age 21 and over': '21+'}, axis='index', inplace=True)\n",
    "\n",
    "asylum_2018_broad_age_total.rename({'Under 16 years': '< 16', \n",
    "                                          '16 to 20 years': '16 - 20', \n",
    "                                          '21 years and over': '21+'}, axis='index', inplace=True)\n",
    "\n",
    "sex_18 = Sex.to_frame(name=\"Lawful 2018\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge LPR and Asyulym seeker datasets\n",
    "\n",
    "# Join asylum datasets together\n",
    "lpr_asylum_sex = asylum_2009_sex.merge(asylum_2018_sex, how=\"inner\", left_index=True, right_index=True)\n",
    "lpr_asylum_age = asylum_2009_broad_age.merge(asylum_2018_broad_age_total, how=\"inner\", left_index=True, right_index=True)\n",
    "lpr_asylum_marital = asylum_2009_marital.merge(asylum_2018_marital, how=\"inner\", left_index=True, right_index=True)\n",
    "\n",
    "# Join LPR datasets together \n",
    "lpr_age = New_index09.merge(Index_age, how=\"inner\", left_index=True, right_index=True)\n",
    "lpr_sex = Sex09.merge(sex_18, how=\"inner\", left_index=True, right_index=True)\n",
    "lpr_marital = Name09.merge(Name18, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up inconsistencies on index and column names\n",
    "\n",
    "for c in lpr_age.index:\n",
    "    lpr_age.rename(index={\n",
    "    c: str(c).strip()\n",
    "}, inplace=True)\n",
    "    \n",
    "lpr_age.rename({'Under 16 years': '< 16', \n",
    "               '16 to 20 years': '16 - 20', \n",
    "               '21 years and over': '21+'}, axis='index', inplace=True)\n",
    "\n",
    "lpr_age.rename({'Lawful Permanent Resident 2009': 'Lawful 2009'})\n",
    "\n",
    "lpr_sex.rename(columns={'LPR 2009': 'Lawful 2009'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpr_asylum_sex = lpr_asylum_sex.merge(lpr_sex, how=\"inner\", left_index=True, right_index=True)\n",
    "lpr_asylum_age = lpr_asylum_age.merge(lpr_age, how=\"inner\", left_index=True, right_index=True)\n",
    "lpr_asylum_marital = lpr_asylum_marital.merge(lpr_marital, how=\"inner\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lpr_asylum_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export cleaned data to Outputs folder\n",
    "\n",
    "filename = 'la_sex.csv'\n",
    "path = os.path.join('.', 'Output_files', filename)\n",
    "lpr_asylum_sex.to_csv(path)\n",
    "\n",
    "filename = 'la_age.csv'\n",
    "path = os.path.join('.', 'Output_files', filename)\n",
    "lpr_asylum_age.to_csv(path)\n",
    "\n",
    "filename = 'la_marital.csv'\n",
    "path = os.path.join('.', 'Output_files', filename)\n",
    "lpr_asylum_marital.to_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacy code for merging datasets ends here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
